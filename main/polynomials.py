from collections import Counter
import threading
import sympy
import utils


LOG = utils.LOG
# How long (in seconds) before we abandon computing Groebner bases?
GROEBNER_TIMEOUT_DEFAULT = .1
UNSET_VAR = None


@utils.log_start_stop
def zero_set(
        polys, symbols, modulus=2,
        subs_dicts=None, existence_only=False,
        groebner_timeout=GROEBNER_TIMEOUT_DEFAULT,
        allow_unset=False):
    """
    Enumerate points in affine space generated by `symbols` in the intersection of the varieties
    determined by the polys. Like most of our code, this is a knock-off of Sivek's lch.sage code.

    We use depth first search so that it if augmentations exist you can more quickly track their existence by watching
    logs from the command line.

    :param polys: List of sympy polynomials. Must have commutative variables.
    :param symbols: List of sympy symbols.
    :param modulus: Coefficient modulus.
    :param subs_dicts: List of dicts mapping symbols to values which we require to be satisfied.
    :param existence_only: Bool. Are we just checking existence?
    :param groebner_timeout: compute Groebner bases until timeout is reached. If failed try larger number of simpler problems.
    :param allow_unset: Bool. If a variable is arbitrary, we make it UNSET_VAR.
    :param log_frequency: int. How often do we log data on loop iteration?
    :return: List of points in the intersection of varieties if existence_only==False else Boolean
        indicating if the zeroset is non-empy.
    """
    LOG.info(f"Searching for zero set of {len(polys)} polynomials in {len(symbols)} variables")
    if modulus == 0:
        raise ValueError("We can only solve for zero sets over Z/mZ with m!=0.")
    if subs_dicts is None:
        subs_dicts = [dict()]
    roots = [
        SolutionSearchNode(
            polys=polys,
            symbols=symbols,
            modulus=modulus,
            subs_dict=subs_dict,
            groebner_timeout=groebner_timeout,
            depth=0,
            allow_unset=allow_unset
        )
        for subs_dict in subs_dicts
    ]
    living_nodes = roots
    solution_nodes = []
    loop_counter = 0
    n_analyzed_nodes = 0
    while True:
        LOG.info(f"{loop_counter}th loop of zero_set search: "
                 f"{len(living_nodes)} living nodes, "
                 f"{n_analyzed_nodes} analyzed nodes, "
                 f"{len(solution_nodes)} solution nodes")
        loop_counter += 1
        if len(living_nodes) == 0:
            break
        else:
            node = living_nodes.pop(0)
            n_analyzed_nodes += 1
            if node.has_solution():
                solution_nodes.append(node)
                # Terminate as early as possible if only checking existence
                if existence_only:
                    return True
            else:
                # Search depth first by spawning at the first unspawned node
                living_nodes = node.get_spawn() + living_nodes
    if existence_only:
        return len(solution_nodes) > 0
    return [node.subs_dict for node in solution_nodes]


def filtered_zero_set(polys, symbols, filtration_levels, modulus=2, groebner_timeout=GROEBNER_TIMEOUT_DEFAULT):
    if modulus == 0:
        raise ValueError("We can only solve for zero sets over Z/mZ with m!=0.")
    f_level_values = sorted(utils.unique_elements(list(filtration_levels.values())))
    f_to_sym = {
        f: {sym for sym in symbols if filtration_levels[sym] == f}
        for f in f_level_values
    }
    cum_sym = set()
    f_to_sym_cum = dict()
    for f in f_level_values:
        cum_sym.update(f_to_sym[f])
        f_to_sym_cum[f] = cum_sym.copy()
    poly_to_symbols = {p: poly_symbols(p) for p in polys}
    f_to_poly = {
        f: {k for k, v in poly_to_symbols.items() if v.issubset(f_to_sym_cum[f])}
        for f in f_level_values
    }
    subs_dicts = [dict()]
    running_symbols = set()
    for f in f_level_values:
        running_symbols.update(f_to_sym[f])
        f_polys = [
            {sympy.Poly(p, *running_symbols, modulus=modulus).subs(d) for p in f_to_poly[f]}
            for d in subs_dicts
        ]
        f_polys_unique = utils.unique_elements(f_polys)
        LOG.info(f"At filtration level={f}: {len(subs_dicts)} prior augmentations give "
                 f"{len(f_polys_unique)} unique extension problems")
        f_polys_index_map = [f_polys_unique.index(p) for p in f_polys]
        extension_subs = [
            zero_set(
                polys=poly_set,
                symbols=f_to_sym[f],
                modulus=modulus,
                groebner_timeout=groebner_timeout
            )
            for poly_set in f_polys_unique
        ]
        new_subs = []
        for i in range(len(subs_dicts)):
            d = subs_dicts[i]
            unique_index = f_polys_index_map[i]
            d_extensions = extension_subs[unique_index]
            for ext in d_extensions:
                new_subs.append({**d, **ext})
        subs_dicts = new_subs
    return subs_dicts


@utils.log_start_stop
def batch_zero_set(polys, symbols, modulus=2, groebner_timeout=GROEBNER_TIMEOUT_DEFAULT, batch_size=10):
    """
    Enumerate points in affine space generated by `symbols` in the intersection of the varieties determined by
    the polys. The batch implementation proceeds by iteratively adding new variables and new polynomials in batches.

    Should only be necessary when there are eg. > 100 polys.

    :param polys: List of sympy polynomials. Must have commutative variables.
    :param symbols: List of sympy symbols.
    :param modulus: Coefficient modulus.
    :param groebner_timeout: compute Groebner bases until timeout is reached.
        If failed try larger number of simpler problems.
    :param batch_size: Size of batches used.
    :return: List of points in the intersection of varieties if existence_only==False else Boolean
        indicating if the zeroset is non-empy.
    """
    LOG.info(f"Searching for (batch) zero set of {len(polys)} polynomials in {len(symbols)} variables")
    if modulus == 0:
        raise ValueError("We can only solve for zero sets over Z/mZ with m!=0.")
    if batch_size <= 0:
        raise ValueError(f"Need batch_size={batch_size} at least 1")
    poly_to_symbols = {p: poly_symbols(p) for p in polys}
    # Frequencies of symbols will help isolate those which occur most often
    ## Could just try to find zeros determined by polynomials having the most frequent symbols
    ## eg. take top 10 symbols appearing most frequently. then polys defined in terms of those symbols
    symbol_freq = Counter()
    for symbol_set in poly_to_symbols.values():
        symbol_freq.update(list(symbol_set))
    symbol_freq = dict(symbol_freq)
    for sym in symbols:
        if sym not in symbol_freq:
            symbol_freq[sym] = 0
    analyzed_polys = []
    analyzed_symbols = set()
    subs_dicts = [dict()]
    loop_counter = 0
    n_analyzed_symbols = 0
    while len(analyzed_polys) < len(polys) and len(subs_dicts) > 0:
        # We want to add new variables so that the ratio of new_polys / new_vars is the highest
        # This pattern gives a hueristic
        unanalyzed_symbols = [x for x in symbols if x not in analyzed_symbols]
        unanalyzed_symbols.sort(key=lambda k: symbol_freq[k])
        new_symbols = []
        new_polys = []
        while len(unanalyzed_symbols) > 0 and len(new_polys) <= batch_size:
            new_symbols.append(unanalyzed_symbols.pop())
            analyzed_symbols.update(set(new_symbols))
            new_polys = [
                k for k, v in poly_to_symbols.items()
                if v.issubset(analyzed_symbols) and k not in analyzed_polys
            ]
        LOG.info(f"Analysis on {loop_counter}th iteration of batch_zero_set:\n"
                 f"    n possible augmentations: {len(subs_dicts)}\n"
                 f"    n analyzed variables: {n_analyzed_symbols}\n"
                 f"    n analyzed polynomials: {len(analyzed_polys)}\n"
                 f"    n new variables: {len(analyzed_symbols) - n_analyzed_symbols}\n"
                 f"    n new polynomials: {len(new_polys)}\n"
                 f"    new polynomials: {new_polys}")
        analyzed_polys += new_polys
        n_analyzed_symbols = len(analyzed_symbols)
        loop_counter += 1
        subs_dicts = zero_set(
            polys=new_polys,
            symbols=list(analyzed_symbols),
            modulus=modulus,
            subs_dicts=subs_dicts,
            groebner_timeout=groebner_timeout,
            allow_unset=True
        )

    return subs_dicts


def ideal_basis(polys, symbols, modulus):
    """Get a simplified basis of the idea generated by polys in GF(modulus)[symbols]"""
    # grlex is much faster than lex! This unbroke some aug searches.
    # sympy has 'buchberger' and 'f5b' methods for Groebner bases. It seems f5b is more up-to-date from googling...
    # https://github.com/sympy/sympy/blob/master/sympy/polys/groebnertools.py
    return utils.unique_elements(
        sympy.GroebnerBasis(polys, *symbols, modulus=modulus, order='grlex', method='f5b').polys
    )


def finite_field_elements(modulus):
    return [n for n in range(modulus)]


def is_linear(poly):
    """Is the polynomial linear? This is not the same as being affine :)

    :param poly: polynomial
    :return: Bool... is linear or not
    """
    if poly == 0:
        return True
    poly = sympy.sympify(poly)
    coeff_dict = poly.as_coefficients_dict()
    for k in list(coeff_dict.keys()):
        if not k.is_symbol:
            return False
    return True


def poly_symbols(poly):
    """Return a list of symbols which appears in a polynomial expression

    :param poly:
    :return:
    """
    # TODO: Requires testing
    output = set()
    poly = sympy.sympify(poly)
    coeff_dict = poly.as_coefficients_dict()
    for k in list(coeff_dict.keys()):
        if k.is_number:
            continue
        for x in k.as_terms()[-1]:
            output.add(x)
    return output


def highest_frequency_symbol(polys, symbols):
    """For a collection of polynomials, find the symbol (variable) which appears which greatest frequency

    :param polys: list of polynomials
    :param symbols: list of symbols
    :return: symbol
    """
    # Ensure that the order of symbols in input match those in polys by re-initializing
    polys = [sympy.Poly(p, *symbols) for p in polys]
    counter = {g: 0 for g in symbols}
    for p in polys:
        monoms = p.monoms()
        for m in monoms:
            for i in range(len(symbols)):
                if m[i] != 0:
                    # Here we are not weighting by powers! I think that this should not make a huge
                    # difference for LCH computations as there should be no monomials divisible
                    # by squares (eg. 1 + x + x*x*y) appearing in a plat.
                    counter[symbols[i]] += 1
    highest_freq = max(counter.values())
    highest_freq_symbols = [g for g in symbols if counter[g] == highest_freq]
    return highest_freq_symbols[0]


class SolutionSearchNode(object):

    def __init__(self, polys, symbols, modulus, subs_dict, depth,
                 groebner_timeout=GROEBNER_TIMEOUT_DEFAULT, allow_unset=False):
        self.polys = [sympy.Poly(p, *symbols, modulus=modulus) for p in polys]
        self.symbols = symbols
        self.modulus = modulus
        self.subs_dict = subs_dict
        self.depth = depth
        self._set_id()
        self.groebner_timeout = groebner_timeout
        self.allow_unset = allow_unset
        self.TERMINAL = False
        self.UNSOLVEABLE = False
        self.ff_elements = finite_field_elements(self.modulus)
        if (len(self.polys) > 0) and (len(self.get_unset_vars()) > 0):
            self._setup_subs()
            self._apply_subs()
            self._unique_polys()
            self._setup_quads()
            self._update_subs_and_polys()
            self._cleanup_subs()
        self._check_unset_vars()

    def get_unset_vars(self):
        """
        :return: list of symbols not already set by self.subs_dict
        """
        return [g for g in self.symbols if g not in self.subs_dict.keys()]

    def has_solution(self):
        """
        :return: Bool for if the node has an already set solution
        """
        return self.TERMINAL and (not self.UNSOLVEABLE)

    def get_spawn(self):
        output = []
        if self.TERMINAL:
            return output
        # We choose the symbol which appears in the most monomials
        g = highest_frequency_symbol(polys=self.polys, symbols=self.get_unset_vars())
        for c in finite_field_elements(modulus=self.modulus):
            subs = self.subs_dict.copy()
            subs[g] = c
            output.append(
                SolutionSearchNode(
                    polys=self.polys,
                    symbols=self.symbols,
                    modulus=self.modulus,
                    subs_dict=subs,
                    depth=self.depth + 1,
                    allow_unset=self.allow_unset
                )
            )
        return output

    def _set_id(self):
        self.id = "{" + f"D={self.depth}:id=" + utils.tiny_id() + "}"

    def _setup_quads(self):
        if self.modulus == 2:
            self._quads = set()
            unset_symbols = self.get_unset_vars()
            for s_1 in unset_symbols:
                for s_2 in unset_symbols:
                    self._quads.add(s_1 * s_2)

    def _setup_subs(self):
        if self.allow_unset:
            keys_to_del = [k for k, v in self.subs_dict.items() if v is UNSET_VAR]
            for k in keys_to_del:
                del self.subs_dict[k]

    def _cleanup_subs(self):
        if self.allow_unset:
            if len(self.polys) == 0:
                for g in self.get_unset_vars():
                    self.subs_dict[g] = UNSET_VAR

    def _check_unset_vars(self):
        if len(self.get_unset_vars()) == 0:
            self.TERMINAL = True

    def _update_subs_and_polys(self):
        """Update self.subs_dict and self.polys

        :return: None
        """
        n_unset_vars = len(self.get_unset_vars())
        if n_unset_vars == 0:
            self.TERMINAL = True
            return
        n_polys = len(self.polys)
        if n_polys == 0:
            return
        LOG.info(f"SolutionSearchNode={self.id}: "
                 f"{n_unset_vars} unset vars & {n_polys} polys")
        while not self.UNSOLVEABLE:
            self._manually_reduce_polys()
            n_old_unset_vars = n_unset_vars
            n_unset_vars = len(self.get_unset_vars())
            # Break if we didn't eliminate any variables
            if n_unset_vars == n_old_unset_vars:
                break
        if self.UNSOLVEABLE:
            self.TERMINAL = True
            return
        if n_unset_vars == 0:
            self.TERMINAL = True
            return
        modified = self._simplify_polys()
        if modified:
            self._update_subs_and_polys()

    def _apply_subs(self, specific_subs=None):
        """Update self.polys by applying substitutions in self.subs_dict or specific_subs

        :param specific_subs: dict or None... substitutions to apply to self.polys
        :return: None
        """
        if specific_subs is not None:
            self.polys = [p.subs(specific_subs) for p in self.polys]
        else:
            self.polys = [p.subs(self.subs_dict) for p in self.polys]

    def _unique_polys(self):
        self.polys = utils.unique_elements(self.polys)

    def _simplify_polys(self):
        """Attempt to simplify ideal for polynomials using Groebner bases until timeout.

        Returns True/False for if self.polys has been modified.

        :return: Bool
        """
        modified = False
        in_main_thread = threading.current_thread() == threading.main_thread()
        thread_timeout = False
        # If not running from the main thread, skip usage of Groebner.
        # For app usage (when we'll be in a worker thread), we have to assume that zero_set args are pretty simple...
        # We need to be in the main thread in order to use utils.timeout_ctx
        if not in_main_thread:
            return False
        def new_ideal_basis():
            with utils.timeout_ctx(self.groebner_timeout):
                return ideal_basis(polys=self.polys, symbols=self.get_unset_vars(), modulus=self.modulus)
        grob_polys = new_ideal_basis()
        if grob_polys is None:
            thread_timeout = True
        if thread_timeout:
            LOG.info(f"SolutionSearchNode={self.id}: Failed to compute Groebner basis")
        else:
            n_polys = len(self.polys)
            n_grob_polys = len(grob_polys)
            if set(self.polys) != set(grob_polys):
                LOG.info(f"SolutionSearchNode={self.id}: "
                         f"Groebner simplified {n_polys} polys to {n_grob_polys}")
                # Groebner can increase sizes of generating sets
                if n_grob_polys <= n_polys:
                    self.polys = grob_polys
                    modified = True
        return modified

    def _manually_reduce_polys(self):
        """Make a single pass over self.polys, checking for affine terms (ax + b)
        Currently this works over Z/2Z. Need to divide by a in general.

        :return: Bool. Are we modifying the set of polynomials?
        """
        n_polys = len(self.polys)
        del_indicies = set()
        modified = False
        for i in range(n_polys):
            p = self.polys[i]
            p_exp = p.as_expr()
            # remove zero polynomials
            if p_exp == 0:
                del_indicies.add(i)
                modified = True
                continue
            # if a poly is non-zero constant, we can never find a zero
            if p_exp.is_number:
                # Must be non-zero due to previous `if`
                self.TERMINAL = True
                self.UNSOLVEABLE = True
                modified = True
                break
            # check for terms of the form p = g - c for g a symbol
            for c in self.ff_elements:
                p_min_c = p_exp - c
                if p_min_c.is_symbol:
                    del_indicies.add(i)
                    self.subs_dict[p_min_c] = c
                    self._apply_subs(specific_subs={p_min_c: c})
                    modified = True
                    break
            # over Z/2Z we can also manually remove quadratic terms.
            # I've seen these come up frequently.
            # p = sym_1 * sym_2 + 1 = 0 => both are 1.
            # we should be able to generalize this to things of the form p = 1 + x_1 * ... * x_k
            # though I don't know how useful it would be
            if self.modulus == 2:
                # this is poorly designed: p_exp + 1 won't be in self._quads,
                # even though elements may agree over Z/2Z
                if p_exp - 1 in self._quads:
                    del_indicies.add(i)
                    # this will extract the individual factors
                    sym_1, sym_2 = (p_exp - 1).as_ordered_factors()
                    self.subs_dict[sym_1] = 1
                    self.subs_dict[sym_2] = 1
                    self._apply_subs(specific_subs={sym_1: 1, sym_2: 1})
                    modified = True
        if modified:
            self.polys = [v for i, v in enumerate(self.polys) if i not in del_indicies]
            self._unique_polys()
        return modified
